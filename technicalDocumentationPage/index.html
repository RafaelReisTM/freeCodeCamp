<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>technicalDocumentationPage</title>
  </head>
  <body>
    <main id="main-doc">
      <nav id="navbar">
        <header><h1>The Python Language Reference</h1></header>
        <ul>
          <li>
            <a class="nav-link">1. Introduction</a>
            <ul>
              <li>1.1. Alternate Implementations</li>
              <li>1.3. Notation</li>
            </ul>
          </li>
          <li>
            <a class="nav-link">2. Lexical analysis</a>
            <ul>
              <li>2.1. Line structure</li>
              <li>2.2. Other tokens</li>
              <li>2.3. Identifiers and keywords</li>
            </ul>
          </li>
          <li><a class="nav-link">3. Data model</a></li>
          <li><a class="nav-link">4. Execution model</a></li>
          <li><a class="nav-link">5. The import system</a></li>
        </ul>
      </nav>
      <section id="1._Introduction" class="main-section">
        <header><h1>1. Introduction</h1></header>
        <p>
          Attention! This page was created solely for the purpose of studying
          HTML and CSS. The information about Python contained on this page is
          incomplete! Link to the complete and official documentation:
          <a href="https://docs.python.org/3/reference/index.html"
            >https://docs.python.org/3/reference/index.html</a
          >
        </p>
        <p>
          This reference manual describes the Python programming language. It is
          not intended as a tutorial. While I am trying to be as precise as
          possible, I chose to use English rather than formal specifications for
          everything except syntax and lexical analysis. This should make the
          document more understandable to the average reader, but will leave
          room for ambiguities. Consequently, if you were coming from Mars and
          tried to re-implement Python from this document alone, you might have
          to guess things and in fact you would probably end up implementing
          quite a different language. On the other hand, if you are using Python
          and wonder what the precise rules about a particular area of the
          language are, you should definitely be able to find them here. If you
          would like to see a more formal definition of the language, maybe you
          could volunteer your time — or invent a cloning machine :-). It is
          dangerous to add too many implementation details to a language
          reference document — the implementation may change, and other
          implementations of the same language may work differently. On the
          other hand, CPython is the one Python implementation in widespread use
          (although alternate implementations continue to gain support), and its
          particular quirks are sometimes worth being mentioned, especially
          where the implementation imposes additional limitations. Therefore,
          you’ll find short “implementation notes” sprinkled throughout the
          text. Every Python implementation comes with a number of built-in and
          standard modules. These are documented in The Python Standard Library.
          A few built-in modules are mentioned when they interact in a
          significant way with the language definition.
        </p>
        <h2>1.1. Alternate Implementations</h2>
        <p>
          Though there is one Python implementation which is by far the most
          popular, there are some alternate implementations which are of
          particular interest to different audiences.
        </p>

        <p>Known implementations include:</p>

        <ul>
          <li>
            CPython
            <p>
              This is the original and most-maintained implementation of Python,
              written in C. New language features generally appear here first.
            </p>
          </li>
          <li>
            Jython
            <p>
              Python implemented in Java. This implementation can be used as a
              scripting language for Java applications, or can be used to create
              applications using the Java class libraries. It is also often used
              to create tests for Java libraries. More information can be found
              at the Jython website.
            </p>
          </li>
          <li>
            Python for .NET
            <p>
              This implementation actually uses the CPython implementation, but
              is a managed .NET application and makes .NET libraries available.
              It was created by Brian Lloyd. For more information, see the
              Python for .NET home page.
            </p>
          </li>
          <li>
            IronPython
            <p>
              An alternate Python for .NET. Unlike Python.NET, this is a
              complete Python implementation that generates IL, and compiles
              Python code directly to .NET assemblies. It was created by Jim
              Hugunin, the original creator of Jython. For more information, see
              the IronPython website.
            </p>
          </li>
          <li>
            PyPy
            <p>
              An implementation of Python written completely in Python. It
              supports several advanced features not found in other
              implementations like stackless support and a Just in Time
              compiler. One of the goals of the project is to encourage
              experimentation with the language itself by making it easier to
              modify the interpreter (since it is written in Python). Additional
              information is available on the PyPy project’s home page.
            </p>
          </li>
        </ul>

        <p>
          Each of these implementations varies in some way from the language as
          documented in this manual, or introduces specific information beyond
          what’s covered in the standard Python documentation. Please refer to
          the implementation-specific documentation to determine what else you
          need to know about the specific implementation you’re using.
        </p>
        <h2>1.3. Notation</h2>
        <p>
          The descriptions of lexical analysis and syntax use a modified
          Backus–Naur form (BNF) grammar notation. This uses the following style
          of definition:
        </p>
        <pre><code>
          name      ::=  lc_letter (lc_letter | "_")*
          lc_letter ::=  "a"..."z"
        </code></pre>
        <p>
          The first line says that a name is an lc_letter followed by a sequence
          of zero or more lc_letters and underscores. An lc_letter in turn is
          any of the single characters 'a' through 'z'. (This rule is actually
          adhered to for the names defined in lexical and grammar rules in this
          document.)
        </p>
        <p>
          Each rule begins with a name (which is the name defined by the rule)
          and ::=. A vertical bar (|) is used to separate alternatives; it is
          the least binding operator in this notation. A star (*) means zero or
          more repetitions of the preceding item; likewise, a plus (+) means one
          or more repetitions, and a phrase enclosed in square brackets ([ ])
          means zero or one occurrences (in other words, the enclosed phrase is
          optional). The * and + operators bind as tightly as possible;
          parentheses are used for grouping. Literal strings are enclosed in
          quotes. White space is only meaningful to separate tokens. Rules are
          normally contained on a single line; rules with many alternatives may
          be formatted alternatively with each line after the first beginning
          with a vertical bar.
        </p>
        <p>
          In lexical definitions (as the example above), two more conventions
          are used: Two literal characters separated by three dots mean a choice
          of any single character in the given (inclusive) range of ASCII
          characters. A phrase between angular brackets (<...>) gives an
          informal description of the symbol defined; e.g., this could be used
          to describe the notion of ‘control character’ if needed.
        </p>
        <p>
          Even though the notation used is almost the same, there is a big
          difference between the meaning of lexical and syntactic definitions: a
          lexical definition operates on the individual characters of the input
          source, while a syntax definition operates on the stream of tokens
          generated by the lexical analysis. All uses of BNF in the next chapter
          (“Lexical Analysis”) are lexical definitions; uses in subsequent
          chapters are syntactic definitions.
        </p>
      </section>
      <section id="2._Lexical_analysis" class="main-section">
        <header><h1>2. Lexical analysis</h1></header>
        <p>
          A Python program is read by a parser. Input to the parser is a stream
          of tokens, generated by the lexical analyzer. This chapter describes
          how the lexical analyzer breaks a file into tokens.
        </p>
        <p>
          Python reads program text as Unicode code points; the encoding of a
          source file can be given by an encoding declaration and defaults to
          UTF-8, see
          <a href="https://peps.python.org/pep-3120/">PEP 3120</a> for details.
          If the source file cannot be decoded, a
          <a
            href="https://docs.python.org/3/library/exceptions.html#SyntaxError"
            >SyntaxError</a
          >
          is raised.
        </p>
        <h2>2.1. Line structure</h2>
        <p>A Python program is divided into a number of logical lines.</p>
        <h3>2.1.1. Logical lines</h3>
        <p>
          The end of a logical line is represented by the token NEWLINE.
          Statements cannot cross logical line boundaries except where NEWLINE
          is allowed by the syntax (e.g., between statements in compound
          statements). A logical line is constructed from one or more physical
          lines by following the explicit or implicit line joining rules.
        </p>
        <h3>2.1.2. Physical lines</h3>
        <p>
          A physical line is a sequence of characters terminated by an
          end-of-line sequence. In source files and strings, any of the standard
          platform line termination sequences can be used - the Unix form using
          ASCII LF (linefeed), the Windows form using the ASCII sequence CR LF
          (return followed by linefeed), or the old Macintosh form using the
          ASCII CR (return) character. All of these forms can be used equally,
          regardless of platform. The end of input also serves as an implicit
          terminator for the final physical line.
        </p>
        <p>
          When embedding Python, source code strings should be passed to Python
          APIs using the standard C conventions for newline characters (the \n
          character, representing ASCII LF, is the line terminator).
        </p>
        <h3>2.1.3. Comments</h3>
        <p>
          A comment starts with a hash character (#) that is not part of a
          string literal, and ends at the end of the physical line. A comment
          signifies the end of the logical line unless the implicit line joining
          rules are invoked. Comments are ignored by the syntax.
        </p>
        <h3>2.1.4. Encoding declarations</h3>
        <p>
          If a comment in the first or second line of the Python script matches
          the regular expression coding[=:]\s*([-\w.]+), this comment is
          processed as an encoding declaration; the first group of this
          expression names the encoding of the source code file. The encoding
          declaration must appear on a line of its own. If it is the second
          line, the first line must also be a comment-only line. The recommended
          forms of an encoding expression are
        </p>
        <pre><code>
          # -*- coding: &lt;encoding-name&gt; -*-
        </code></pre>
        <p>which is recognized also by GNU Emacs, and</p>
        <pre><code>
          # vim:fileencoding=&lt;encoding-name&gt;
        </code></pre>
        <p>which is recognized by Bram Moolenaar’s VIM.</p>
        <p>
          If no encoding declaration is found, the default encoding is UTF-8. If
          the implicit or explicit encoding of a file is UTF-8, an initial UTF-8
          byte-order mark (b’xefxbbxbf’) is ignored rather than being a syntax
          error.
        </p>
        <p>
          If an encoding is declared, the encoding name must be recognized by
          Python (see Standard Encodings). The encoding is used for all lexical
          analysis, including string literals, comments and identifiers.
        </p>
        <h3>2.1.5. Explicit line joining</h3>
        <p>
          Two or more physical lines may be joined into logical lines using
          backslash characters (\), as follows: when a physical line ends in a
          backslash that is not part of a string literal or comment, it is
          joined with the following forming a single logical line, deleting the
          backslash and the following end-of-line character. For example:
        </p>
        <pre><code>
          if 1900 < year < 2100 and 1 <= month <= 12 \
              and 1 <= day <= 31 and 0 <= hour < 24 \
              and 0 <= minute < 60 and 0 <= second < 60:   # Looks like a valid date
                    return 1
        </code></pre>
        <p>
          A line ending in a backslash cannot carry a comment. A backslash does
          not continue a comment. A backslash does not continue a token except
          for string literals (i.e., tokens other than string literals cannot be
          split across physical lines using a backslash). A backslash is illegal
          elsewhere on a line outside a string literal.
        </p>
        <h3>2.1.6. Implicit line joining</h3>
        <p>
          Expressions in parentheses, square brackets or curly braces can be
          split over more than one physical line without using backslashes. For
          example:
        </p>
        <pre><code>
          month_names = ['Januari', 'Februari', 'Maart',      # These are the
                         'April',   'Mei',      'Juni',       # Dutch names
                         'Juli',    'Augustus', 'September',  # for the months
                         'Oktober', 'November', 'December']   # of the year
        </code></pre>
        <p>
          Implicitly continued lines can carry comments. The indentation of the
          continuation lines is not important. Blank continuation lines are
          allowed. There is no NEWLINE token between implicit continuation
          lines. Implicitly continued lines can also occur within triple-quoted
          strings (see below); in that case they cannot carry comments.
        </p>
        <h3>2.1.7. Blank lines</h3>
        <p>
          A logical line that contains only spaces, tabs, formfeeds and possibly
          a comment, is ignored (i.e., no NEWLINE token is generated). During
          interactive input of statements, handling of a blank line may differ
          depending on the implementation of the read-eval-print loop. In the
          standard interactive interpreter, an entirely blank logical line (i.e.
          one containing not even whitespace or a comment) terminates a
          multi-line statement.
        </p>
        <h3>2.1.8. Indentation</h3>
        <p>
          Leading whitespace (spaces and tabs) at the beginning of a logical
          line is used to compute the indentation level of the line, which in
          turn is used to determine the grouping of statements.
        </p>
        <p>
          Tabs are replaced (from left to right) by one to eight spaces such
          that the total number of characters up to and including the
          replacement is a multiple of eight (this is intended to be the same
          rule as used by Unix). The total number of spaces preceding the first
          non-blank character then determines the line’s indentation.
          Indentation cannot be split over multiple physical lines using
          backslashes; the whitespace up to the first backslash determines the
          indentation.
        </p>
        <p>
          Indentation is rejected as inconsistent if a source file mixes tabs
          and spaces in a way that makes the meaning dependent on the worth of a
          tab in spaces; a TabError is raised in that case.
        </p>
        <p>
          <span class="bold-text">Cross-platform compatibility note:</span>
          because of the nature of text editors on non-UNIX platforms, it is
          unwise to use a mixture of spaces and tabs for the indentation in a
          single source file. It should also be noted that different platforms
          may explicitly limit the maximum indentation level.
        </p>
        <p>
          A formfeed character may be present at the start of the line; it will
          be ignored for the indentation calculations above. Formfeed characters
          occurring elsewhere in the leading whitespace have an undefined effect
          (for instance, they may reset the space count to zero).
        </p>
        <p>
          The indentation levels of consecutive lines are used to generate
          INDENT and DEDENT tokens, using a stack, as follows.
        </p>
        <p>
          Before the first line of the file is read, a single zero is pushed on
          the stack; this will never be popped off again. The numbers pushed on
          the stack will always be strictly increasing from bottom to top. At
          the beginning of each logical line, the line’s indentation level is
          compared to the top of the stack. If it is equal, nothing happens. If
          it is larger, it is pushed on the stack, and one INDENT token is
          generated. If it is smaller, it must be one of the numbers occurring
          on the stack; all numbers on the stack that are larger are popped off,
          and for each number popped off a DEDENT token is generated. At the end
          of the file, a DEDENT token is generated for each number remaining on
          the stack that is larger than zero.
        </p>
        <p>
          Here is an example of a correctly (though confusingly) indented piece
          of Python code:
        </p>
        <pre><code>
          def perm(l):
                  # Compute the list of all permutations of l
              if len(l) &lt;= 1:
                            return [l]
              r = []
              for i in range(len(l)):
                      s = l[:i] + l[i+1:]
                      p = perm(s)
                      for x in p:
                        r.append(l[i:i+1] + x)
              return r
        </code></pre>
        <p>The following example shows various indentation errors:</p>
        <pre><code>
          def perm(l):                            # error: first line indented
              for i in range(len(l)):             # error: not indented
                  s = l[:i] + l[i+1:]
                      p = perm(l[:i] + l[i+1:])   # error: unexpected indent
                      for x in p:
                              r.append(l[i:i+1] + x)
                          return r                # error: inconsistent dedent
        </code></pre>
        <p>
          (Actually, the first three errors are detected by the parser; only the
          last error is found by the lexical analyzer — the indentation of
          "return r" does not match a level popped off the stack.)
        </p>
        <h3>2.1.9. Whitespace between tokens</h3>
        <p>
          Except at the beginning of a logical line or in string literals, the
          whitespace characters space, tab and formfeed can be used
          interchangeably to separate tokens. Whitespace is needed between two
          tokens only if their concatenation could otherwise be interpreted as a
          different token (e.g., ab is one token, but a b is two tokens).
        </p>
        <h2>2.2. Other tokens</h2>
        <p>
          Besides NEWLINE, INDENT and DEDENT, the following categories of tokens
          exist: identifiers, keywords, literals, operators, and delimiters.
          Whitespace characters (other than line terminators, discussed earlier)
          are not tokens, but serve to delimit tokens. Where ambiguity exists, a
          token comprises the longest possible string that forms a legal token,
          when read from left to right.
        </p>
        <h2>2.3. Identifiers and keywords</h2>
        <p>
          Identifiers (also referred to as names) are described by the following
          lexical definitions.
        </p>
        <p>
          The syntax of identifiers in Python is based on the Unicode standard
          annex UAX-31, with elaboration and changes as defined below; see also
          <a href="https://peps.python.org/pep-3131/">PEP 3131</a> for further
          details.
        </p>
        <p>
          Within the ASCII range (U+0001..U+007F), the valid characters for
          identifiers are the same as in Python 2.x: the uppercase and lowercase
          letters "A" through "Z", the underscore "_" and, except for the first
          character, the digits "0" through "9".
        </p>
        <p>
          Python 3.0 introduces additional characters from outside the ASCII
          range (see <a href="https://peps.python.org/pep-3131/">PEP 3131</a>).
          For these characters, the classification uses the version of the
          Unicode Character Database as included in the
          <a
            href="https://docs.python.org/3/library/unicodedata.html#module-unicodedata"
            >unicodedata</a
          >
          module.
        </p>
        <p>Identifiers are unlimited in length. Case is significant.</p>
        <pre><code>
          identifier   ::=  xid_start xid_continue*
          id_start     ::=  &lt;all characters in general categories Lu, Ll, Lt, Lm, Lo, Nl, the underscore, and characters with the Other_ID_Start property&gt;
          id_continue  ::=  &lt;all characters in id_start, plus characters in the categories Mn, Mc, Nd, Pc and others with the Other_ID_Continue property&gt;
          xid_start    ::=  &lt;all characters in id_start whose NFKC normalization is in "id_start xid_continue*"&gt;
          xid_continue ::=  &lt;all characters in id_continue whose NFKC normalization is in "id_continue*"&gt;
        </code></pre>
        <p>The Unicode category codes mentioned above stand for:</p>
        <ul>
          <li>Lu - uppercase letters</li>
          <li>Ll - lowercase letters</li>
          <li>Lt - titlecase letters</li>
          <li>Lm - modifier letters</li>
          <li>Lo - other letters</li>
          <li>Nl - letter numbers</li>
          <li>Mn - nonspacing marks</li>
          <li>Mc - spacing combining marks</li>
          <li>Nd - decimal numbers</li>
          <li>Pc - connector punctuations</li>
          <li>
            Other_ID_Start - explicit list of characters in PropList.txt to
            support backwards compatibility
          </li>
          <li>Other_ID_Continue - likewise</li>
        </ul>
        <p>
          All identifiers are converted into the normal form NFKC while parsing;
          comparison of identifiers is based on NFKC.
        </p>
        <p>
          A non-normative HTML file listing all valid identifier characters for
          Unicode 15.0.0 can be found at
          <a
            href="https://www.unicode.org/Public/15.0.0/ucd/DerivedCoreProperties.txt"
            >https://www.unicode.org/Public/15.0.0/ucd/DerivedCoreProperties.txt</a
          >
        </p>
        <h3>2.3.1 Keywords</h3>
        <p>
          The following identifiers are used as reserved words, or keywords of
          the language, and cannot be used as ordinary identifiers. They must be
          spelled exactly as written here:
        </p>
        <pre><code>
          False      await      else       import     pass
          None       break      except     in         raise
          True       class      finally    is         return
          and        continue   for        lambda     try
          as         def        from       nonlocal   while
          assert     del        global     not        with
          async      elif       if         or         yield
        </code></pre>
        <h3>2.3.2. Soft Keywords</h3>
        <p>
          Some identifiers are only reserved under specific contexts. These are
          known as soft keywords. The identifiers "match", "case", "type" and
          "_" can syntactically act as keywords in certain contexts, but this
          distinction is done at the parser level, not when tokenizing.
        </p>
        <p>
          As soft keywords, their use in the grammar is possible while still
          preserving compatibility with existing code that uses these names as
          identifier names.
        </p>
        <p>
          "match", "case", and "_" are used in the
          <a
            href="https://docs.python.org/3/reference/compound_stmts.html#match"
            >match</a
          >
          statement. "type" is used in the
          <a href="https://docs.python.org/3/reference/simple_stmts.html#type"
            >type</a
          >
          statement.
        </p>
      </section>
      <section id="3._Data_model" class="main-section">
        <header><h1>3. Data model</h1></header>
        <h2>Lorem Ipsum</h2>
        <p>
          Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse
          luctus lorem in posuere volutpat. Duis efficitur vestibulum accumsan.
          Nunc quis ullamcorper orci. Mauris mollis leo id nunc hendrerit
          interdum. Aenean sed sollicitudin augue. Proin dignissim enim vel
          lobortis dignissim. In hac habitasse platea dictumst
        </p>
      </section>
      <section id="4._Execution_model" class="main-section">
        <header><h1>4. Execution model</h1></header>
        <h2>Lorem Ipsum</h2>
        <p>
          Maecenas dignissim sed nulla sit amet sodales. Donec eget metus erat.
          Nunc scelerisque blandit semper. Nulla quis feugiat lacus. Proin orci
          dolor, mollis sed sapien quis, efficitur aliquet diam. Aliquam maximus
          varius risus dictum auctor. Vestibulum porta felis dolor, eget
          vestibulum sapien tempor venenatis. Maecenas vehicula, enim et viverra
          condimentum, velit odio tempor sapien, nec commodo lorem nulla eu
          felis. Duis et laoreet augue, nec tempus urna. Maecenas at lacus non
          erat pulvinar tincidunt. Duis eget finibus libero
        </p>
      </section>
      <section id="5._The_import_system" class="main-section">
        <header><h1>5. The import system</h1></header>
        <h2>Lorem Ipsum</h2>
        <p>
          Morbi tincidunt venenatis elit, lacinia pretium tortor suscipit vitae.
          Pellentesque id nisi dapibus, luctus ante nec, vulputate erat. Mauris
          aliquet, nunc vel tempor imperdiet, nunc nisl feugiat quam, sit amet
          imperdiet quam urna vel turpis. Aenean bibendum ultricies ipsum a
          pharetra. Donec id mi lectus. Phasellus sagittis sed dolor a suscipit.
          Nam elit eros, luctus eu ligula a, semper ornare diam. Interdum et
          malesuada fames ac ante ipsum primis in faucibus. Morbi ac varius
          lorem, ac dapibus magna. Sed vitae erat vitae quam venenatis
          condimentum sed sed neque. Pellentesque habitant morbi tristique
          senectus et netus et malesuada fames ac turpis egestas. Quisque erat
          dui, condimentum at dictum vitae, pharetra sit amet felis. Cras ac
          blandit enim, pharetra vestibulum elit. Praesent non lectus porttitor,
          aliquam ipsum at, tincidunt
        </p>
      </section>
    </main>
  </body>
</html>
